{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "gpt2_text_classification_finetune_torch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_3gWXQ1Im-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gluonnlp\n",
        "!pip install transformers\n",
        "!pip install mxnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21pTmEPzJOY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') \n",
        "\n",
        "os.chdir('insert your own path')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE3iYxsVGvfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import gluonnlp as nlp\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from transformers import *\n",
        "from kogpt2.pytorch_kogpt2 import get_pytorch_kogpt2_model\n",
        "from kogpt2.utils import get_tokenizer\n",
        "from gluonnlp.data import SentencepieceTokenizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wRcw-I9urxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AFmzbJwr-53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xASgCsazJ-dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
        "!wget https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQjHElLmKGeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train = nlp.data.TSVDataset(\"ratings_train.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)\n",
        "dataset_test = nlp.data.TSVDataset(\"ratings_test.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDyuasyEKLI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok_path = get_tokenizer()\n",
        "model_gpt, vocab, config = get_pytorch_kogpt2_model()\n",
        "tok = nlp.data.BERTSPTokenizer(tok_path, vocab, lower=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQwnDdCFLLXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, gpt2,\n",
        "                 max_len, pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            gpt2, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgezpjybNR4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Setting parameters\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYztFESeNSRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = GPT2Dataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = GPT2Dataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbKNVjLWZj8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7tAj9_QaZYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in train_dataloader:\n",
        "    print(i)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW58WyjUqFfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# attention mask 삭제\n",
        "class GPT2Classifier(nn.Module):\n",
        "    def __init__(self, gpt2, hidden_size = 768, num_classes = 2, dr_rate = None, params = None):\n",
        "        super(GPT2Classifier, self).__init__()\n",
        "        self.gpt2 = gpt2 # pre_trained model\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p = dr_rate)\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "\n",
        "        _, hidden_output = self.gpt2(input_ids=token_ids, token_type_ids=segment_ids.long())\n",
        "        pooled_output = hidden_output[:,-1]\n",
        "        # pooler_output = pooler_out[0][:,-1] ## transformers 모듈을 사용할 경우\n",
        "\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooled_output)\n",
        "\n",
        "        return self.classifier(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85lnX2qpGna8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GPT2Classifier(model_gpt, dr_rate = 0.5).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjEPm6dbGnbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_MNqRC2GnbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCKlgpZSGnbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xINPiZg5GnbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jna7UciAGnbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hLIU4SwGnbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length = valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
        "\n",
        "    with open('checkpoint/checkpoint_{}.model'.format(str(e + 1).zfill(2)), 'wb') as f:\n",
        "        torch.save(model.state_dict(), f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCjkv2n3GnbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWx7dYpYGnbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKg8A9TmGnbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E53r_C6hGnbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCeeq1V8Gnbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9PebR1PGnbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}